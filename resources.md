# Resources: Post-Training & Alignment

> Curated learning materials organized by topic for building LLM training expertise.

---

## üìö Training Playbooks & Guides

- [**Smol Training Playbook**](https://huggingface.co/spaces/HuggingFaceTB/smol-training-playbook) ‚Äî HuggingFace's comprehensive guide to training small LLMs
- [**LLM Course**](https://github.com/mlabonne/llm-course) ‚Äî Complete roadmap to LLM engineering by Maxime Labonne
- [**RLHF Book**](https://rlhfbook.com/) ‚Äî Nathan Lambert's free book on RLHF

---

## üèõÔ∏è Foundational Papers

### Transformers & Pre-training
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) ‚Äî Original Transformer paper
- [GPT-3: Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) ‚Äî OpenAI's scaling paper
- [LLaMA](https://arxiv.org/abs/2302.13971) ‚Äî Meta's efficient pre-training recipe

### RLHF & Alignment
- [InstructGPT (RLHF)](https://arxiv.org/abs/2203.02155) ‚Äî OpenAI's original RLHF paper
- [Constitutional AI](https://arxiv.org/abs/2212.08073) ‚Äî Anthropic's RLAIF approach
- [DPO: Direct Preference Optimization](https://arxiv.org/abs/2305.18290) ‚Äî RL-free preference learning
- [KTO: Model Alignment as Prospect Theoretic Optimization](https://arxiv.org/abs/2402.01306) ‚Äî Kahneman-Tversky optimization

### Reasoning & RL
- [DeepSeek-R1](https://arxiv.org/abs/2501.12948) ‚Äî GRPO for reasoning models
- [Let's Verify Step by Step](https://arxiv.org/abs/2305.20050) ‚Äî Process reward models
- [STaR: Self-Taught Reasoner](https://arxiv.org/abs/2203.14465) ‚Äî Bootstrapping reasoning

### Synthetic Data
- [Self-Instruct](https://arxiv.org/abs/2212.10560) ‚Äî Generating instruction data
- [Evol-Instruct (WizardLM)](https://arxiv.org/abs/2304.12244) ‚Äî Evolving instruction complexity
- [Orca 2](https://arxiv.org/abs/2311.11045) ‚Äî Teaching small models to reason

### Infrastructure & Efficiency
- [LoRA](https://arxiv.org/abs/2106.09685) ‚Äî Low-Rank Adaptation for efficient fine-tuning
- [S-LoRA](https://arxiv.org/abs/2311.03285) ‚Äî Multi-tenant LoRA serving at scale
- [Flash Attention](https://arxiv.org/abs/2205.14135) ‚Äî IO-aware exact attention
- [Speculative Decoding](https://arxiv.org/abs/2211.17192) ‚Äî Accelerating LLM inference

---

## üîß Tools & Frameworks

### Fine-Tuning
- [**Unsloth**](https://github.com/unslothai/unsloth) ‚Äî 2x faster LoRA with 70% less VRAM
- [**Axolotl**](https://github.com/OpenAccess-AI-Collective/axolotl) ‚Äî YAML-driven training pipelines
- [**LLaMA-Factory**](https://github.com/hiyouga/LLaMA-Factory) ‚Äî Web UI for fine-tuning
- [**TRL**](https://github.com/huggingface/trl) ‚Äî HuggingFace's RLHF library
- [**mergekit**](https://github.com/arcee-ai/mergekit) ‚Äî Model merging (TIES, DARE, SLERP)

### Inference & Serving
- [**vLLM**](https://github.com/vllm-project/vllm) ‚Äî High-throughput serving with PagedAttention
- [**SGLang**](https://github.com/sgl-project/sglang) ‚Äî Structured generation + RadixAttention
- [**llama.cpp**](https://github.com/ggerganov/llama.cpp) ‚Äî CPU/edge inference with GGUF
- [**Ollama**](https://ollama.ai/) ‚Äî Local model deployment made easy

### Training Optimizations
- [**Flash Attention**](https://github.com/Dao-AILab/flash-attention) ‚Äî Memory-efficient attention
- [**DeepSpeed**](https://github.com/microsoft/DeepSpeed) ‚Äî Distributed training at scale

### Evaluation
- [**lm-eval-harness**](https://github.com/EleutherAI/lm-evaluation-harness) ‚Äî Standard benchmark suite
- [**BFCL**](https://gorilla.cs.berkeley.edu/leaderboard.html) ‚Äî Berkeley Function Calling Leaderboard
- [**DeepEval**](https://github.com/confident-ai/deepeval) ‚Äî LLM evaluation framework

---

## üéì Courses & Lectures

- [**Karpathy: Let's build GPT**](https://www.youtube.com/watch?v=kCc8FmEb1nY) ‚Äî Build GPT from scratch (2hr)
- [**Karpathy: nanoGPT**](https://github.com/karpathy/nanoGPT) ‚Äî Minimal GPT training code
- [**Stanford CS224N**](https://web.stanford.edu/class/cs224n/) ‚Äî NLP with Deep Learning
- [**Full Stack LLM Bootcamp**](https://fullstackdeeplearning.com/llm-bootcamp/) ‚Äî Production LLM engineering

---

## üìù Technical Blogs

### OpenAI
- [ChatGPT](https://openai.com/index/chatgpt/) ‚Äî Original ChatGPT announcement
- [GPT-4 Technical Report](https://openai.com/index/gpt-4-research/)
- [Scaling Laws](https://openai.com/index/scaling-laws-for-neural-language-models/)

### Anthropic
- [Claude's Character](https://www.anthropic.com/research/claude-character)
- [Core Views on AI Safety](https://www.anthropic.com/research/core-views-on-ai-safety)

### Others
- [Chip Huyen's Blog](https://huyenchip.com/blog/) ‚Äî ML systems & LLM engineering
- [Sebastian Raschka](https://magazine.sebastianraschka.com/) ‚Äî LLM fundamentals
- [Lil'Log (Lilian Weng)](https://lilianweng.github.io/) ‚Äî Deep dives on RL, transformers

---

## üí¨ Communities

- [**r/LocalLLaMA**](https://reddit.com/r/LocalLLaMA) ‚Äî Local model running & fine-tuning
- [**Latent Space Podcast**](https://www.latent.space/) ‚Äî AI engineering podcast
- [**HuggingFace Discord**](https://discord.gg/huggingface) ‚Äî Model training discussions

---

## üìä Model Hubs & Datasets

- [**HuggingFace Hub**](https://huggingface.co/models) ‚Äî Model repository
- [**Open LLM Leaderboard**](https://huggingface.co/spaces/HuggingFaceh4/open_llm_leaderboard) ‚Äî Model benchmarks
- [**Anthropic HH-RLHF**](https://huggingface.co/datasets/Anthropic/hh-rlhf) ‚Äî Human preference data
- [**OpenAssistant**](https://huggingface.co/datasets/OpenAssistant/oasst2) ‚Äî Conversation data
