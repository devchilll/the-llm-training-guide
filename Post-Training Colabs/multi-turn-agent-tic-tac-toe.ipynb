{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/devchilll/the-llm-training-guide/blob/main/Post-Training%20Colabs/multi-turn-agent-tic-tac-toe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qz27EIErl206"
   },
   "source": [
    "### Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PrfB6bs4l207"
   },
   "outputs": [],
   "source": [
    "# Portions adapted from Unsloth Notebooks (https://github.com/unslothai/notebooks)\n",
    "# Copyright (c) Unsloth contributors.\n",
    "# License: GNU LGPL v3.0.\n",
    "# Modifications by OpenPipe:\n",
    "# - switched to uv\n",
    "# - changed vllm/triton pinning logic\n",
    "# - added protobuf pins\n",
    "# See /licenses/LGPL-3.0.txt and /licenses/GPL-3.0.txt for full text.\n",
    "\n",
    "%%capture\n",
    "import os\n",
    "\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !uv pip install openpipe-art[backend]==0.5.9 --prerelease allow --no-cache-dir\n",
    "else:\n",
    "    try:\n",
    "        import numpy\n",
    "\n",
    "        get_numpy = f\"numpy=={numpy.__version__}\"\n",
    "    except:\n",
    "        get_numpy = \"numpy\"\n",
    "    try:\n",
    "        import subprocess\n",
    "\n",
    "        is_t4 = \"Tesla T4\" in str(subprocess.check_output([\"nvidia-smi\"]))\n",
    "    except:\n",
    "        is_t4 = False\n",
    "    get_vllm, get_triton = (\n",
    "        (\"vllm==0.9.2\", \"triton==3.2.0\") if is_t4 else (\"vllm\", \"triton\")\n",
    "    )\n",
    "    !uv pip install --upgrade \\\n",
    "        openpipe-art[backend]==0.4.11 pillow==11.3.0 protobuf==5.29.5 {get_vllm} {get_numpy} --prerelease allow --no-cache-dir\n",
    "    !uv pip install -qqq {get_triton}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Rgig3e2l208"
   },
   "source": [
    "### Environment Variables\n",
    "\n",
    "Later on in the notebook, we'll be creating a model that can automatically logs metrics and chat completions to Weights & Biases. In order to do so, you'll need to provide your Weights & Biases API key as an environment variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Vll9CZlYl209"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Optional\n",
    "WANDB_API_KEY = \"\"\n",
    "if WANDB_API_KEY:\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBWkQ7Yyl209"
   },
   "source": [
    "### Agentic Environment\n",
    "\n",
    "<a name=\"Environment\"></a>\n",
    "\n",
    "ART allows your agent to learn by interacting with its environment. In this example, we'll create an environment in which the agent can play tic tac toe.\n",
    "\n",
    "Feel free to read as much or as little of this section's code as you'd like. The important thing to understand is that we're defining the rules of this agent's environment. In many cases, this will already be defined by the task you're trying to solve, but if you need to define a custom environment, this is how you do it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2-wircX1l20-"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Literal, TypedDict\n",
    "\n",
    "\n",
    "class TicTacToeGame(TypedDict):\n",
    "    board: list[list[str]]\n",
    "    agent_symbol: Literal[\"x\", \"o\"]\n",
    "    opponent_symbol: Literal[\"x\", \"o\"]\n",
    "\n",
    "\n",
    "def generate_game(board_length: int = 3) -> TicTacToeGame:\n",
    "    board = [[\"_\" for _ in range(board_length)] for _ in range(board_length)]\n",
    "    agent_symbol = random.choice([\"x\", \"o\"])\n",
    "    opponent_symbol = \"x\" if agent_symbol == \"o\" else \"o\"\n",
    "    return {\n",
    "        \"board\": board,\n",
    "        \"agent_symbol\": agent_symbol,\n",
    "        \"opponent_symbol\": opponent_symbol,\n",
    "    }\n",
    "\n",
    "\n",
    "def render_board(game: TicTacToeGame) -> str:\n",
    "    board = game[\"board\"]\n",
    "    board_length = len(board)\n",
    "    # print something like this:\n",
    "    #    1   2   3\n",
    "    # A  _ | x | x\n",
    "    # B  o | _ | _\n",
    "    # C  _ | o | _\n",
    "    # where _ is an empty cell\n",
    "\n",
    "    board_str = \"   \" + \"   \".join([str(i + 1) for i in range(board_length)]) + \"\\n\"\n",
    "    for i in range(board_length):\n",
    "        board_str += f\"{chr(65 + i)}  {board[i][0]} | {board[i][1]} | {board[i][2]}\\n\"\n",
    "    return board_str\n",
    "\n",
    "\n",
    "def get_opponent_move(game: TicTacToeGame) -> tuple[int, int]:\n",
    "    # get a random empty cell\n",
    "    empty_cells = [\n",
    "        (i, j) for i in range(3) for j in range(3) if game[\"board\"][i][j] == \"_\"\n",
    "    ]\n",
    "    return random.choice(empty_cells)\n",
    "\n",
    "\n",
    "def apply_agent_move(game: TicTacToeGame, move: str) -> None:\n",
    "    board_length = len(game[\"board\"])\n",
    "\n",
    "    try:\n",
    "        root = ET.fromstring(move)\n",
    "        square = root.text\n",
    "    except Exception:\n",
    "        raise ValueError(\"Invalid xml\")\n",
    "\n",
    "    try:\n",
    "        row_index = ord(square[0]) - 65\n",
    "        col_index = int(square[1]) - 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise ValueError(\"Unable to parse square\")\n",
    "\n",
    "    if (\n",
    "        row_index < 0\n",
    "        or row_index >= board_length\n",
    "        or col_index < 0\n",
    "        or col_index >= board_length\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            f\"Invalid move, row or column out of bounds: {row_index}, {col_index}\"\n",
    "        )\n",
    "\n",
    "    # check if the move is valid\n",
    "    if game[\"board\"][row_index][col_index] != \"_\":\n",
    "        raise ValueError(\"Square already occupied\")\n",
    "\n",
    "    game[\"board\"][row_index][col_index] = game[\"agent_symbol\"]\n",
    "\n",
    "\n",
    "def check_winner(board: list[list[str]]) -> Literal[\"x\", \"o\", \"draw\", None]:\n",
    "    board_length = len(board)\n",
    "    # check rows\n",
    "    for row in board:\n",
    "        if row.count(row[0]) == board_length and row[0] != \"_\":\n",
    "            return row[0]\n",
    "    # check columns\n",
    "    for col in range(board_length):\n",
    "        if [board[row][col] for row in range(board_length)].count(\n",
    "            board[0][col]\n",
    "        ) == board_length and board[0][col] != \"_\":\n",
    "            return board[0][col]\n",
    "\n",
    "    # top right to bottom left\n",
    "    upward_diagonal = [board[i][board_length - i - 1] for i in range(board_length)]\n",
    "    if (\n",
    "        upward_diagonal.count(upward_diagonal[0]) == board_length\n",
    "        and upward_diagonal[0] != \"_\"\n",
    "    ):\n",
    "        return upward_diagonal[0]\n",
    "\n",
    "    # top left to bottom right\n",
    "    downward_diagonal = [board[i][i] for i in range(board_length)]\n",
    "    if (\n",
    "        downward_diagonal.count(downward_diagonal[0]) == board_length\n",
    "        and downward_diagonal[0] != \"_\"\n",
    "    ):\n",
    "        return downward_diagonal[0]\n",
    "\n",
    "    # check for draw\n",
    "    if all(cell != \"_\" for row in board for cell in row):\n",
    "        return \"draw\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X01OP47bl20_"
   },
   "source": [
    "### Creating a Model\n",
    "\n",
    "Now that we've defined the rules of our environment, we can create a model that will learn to play 2048. We'll use a Qwen 2.5 3B model for this example. The `name` parameter will be associated with a wandb run, and the `base_model` parameter is the model that we'll be training a LoRA on top of.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gw-kdzoNl21A",
    "outputId": "188e37df-1187-4ec1-c765-40f3321dd4b2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "import art\n",
    "from art.local import LocalBackend\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "backend = LocalBackend(path=\"./.art\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubGriXoPl21B"
   },
   "source": [
    "### Creating a Model\n",
    "\n",
    "Now that we've defined the rules of our environment, we can create a model that will learn to play tic tac toe. We'll use a Qwen 2.5 3B model for this example. The `name` parameter will be associated with a wandb run, and the `base_model` parameter is the model that we'll be training a LoRA on top of.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtwVGF2al21B",
    "outputId": "7aa3c765-a806-4e29-c063-639e4f0c20b2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:torchao:Skipping import of cpp extensions due to incompatible torch version 2.7.0+cu126 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info\n",
      "/usr/local/lib/python3.12/dist-packages/torchao/quantization/quant_api.py:2525: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  * regex for parameter names, must start with `re:`, e.g. `re:language\\.layers\\..+\\.q_proj.weight`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO 02-08 19:28:53 [__init__.py:244] Automatically detected platform cuda.\n",
      "ERROR 02-08 19:28:55 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model = art.TrainableModel(\n",
    "    name=\"001-script\",\n",
    "    project=\"tic-tac-toe\",\n",
    "    base_model=\"Qwen/Qwen2.5-3B-Instruct\",\n",
    ")\n",
    "await model.register(backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1QehBWwl21B"
   },
   "source": [
    "### Defining a Rollout\n",
    "\n",
    "<a name=\"Rollout\"></a>\n",
    "\n",
    "A rollout is a single episode of an agent performing its task. It generates one or more trajectories, which are lists of messages and choices.\n",
    "\n",
    "In this example, the rollout function generates a game of tic tac toe, and the agent plays it until the game is finished. It then returns a trajectory which contains all the `system` and `user` messages presented to the agent, as well as all the `choices` that the agent made.\n",
    "\n",
    "When the game is finished the `reward` for the agent's performance is calculated based on whether the agent won, lost, drew, or errored, which is then assigned to the trajectory.\n",
    "\n",
    "This rollout function will be called many times in parallel during each step of the training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Dwm-ElaXl21C"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import openai\n",
    "import weave\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import art\n",
    "\n",
    "if os.getenv(\"WANDB_API_KEY\", \"\"):\n",
    "    print(\"initializing weave\")\n",
    "    weave.init(model.project, settings={\"print_call_link\": False})\n",
    "\n",
    "\n",
    "class TicTacToeScenario(BaseModel):\n",
    "    step: int\n",
    "\n",
    "\n",
    "@weave.op\n",
    "@art.retry(exceptions=(openai.LengthFinishReasonError,))\n",
    "async def rollout(model: art.Model, scenario: TicTacToeScenario) -> art.Trajectory:\n",
    "    game = generate_game()\n",
    "\n",
    "    trajectory = art.Trajectory(\n",
    "        messages_and_choices=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You are a tic-tac-toe player. You are playing against an opponent. Always choose the move most likely to lead to an eventual win. Return your move as an XML object with a single property 'move', like so: <move>A1</move>. Optional moves are 'A1', 'B3', 'C2', etc. You are the {game['agent_symbol']} symbol.\",\n",
    "            }\n",
    "        ],\n",
    "        metadata={\n",
    "            \"notebook-id\": \"tic-tac-toe\",\n",
    "            \"step\": scenario.step,\n",
    "        },\n",
    "        reward=0,\n",
    "    )\n",
    "\n",
    "    move_number = 0\n",
    "\n",
    "    if game[\"agent_symbol\"] == \"o\":\n",
    "        starting_opponent_move = get_opponent_move(game)\n",
    "        game[\"board\"][starting_opponent_move[0]][starting_opponent_move[1]] = game[\n",
    "            \"opponent_symbol\"\n",
    "        ]\n",
    "\n",
    "    while check_winner(game[\"board\"]) is None:\n",
    "        trajectory.messages_and_choices.append(\n",
    "            {\"role\": \"user\", \"content\": render_board(game)}\n",
    "        )\n",
    "\n",
    "        messages = trajectory.messages()\n",
    "\n",
    "        try:\n",
    "            client = AsyncOpenAI(\n",
    "                base_url=model.inference_base_url,\n",
    "                api_key=model.inference_api_key,\n",
    "            )\n",
    "\n",
    "            chat_completion = await client.chat.completions.create(\n",
    "                model=model.get_inference_name(),\n",
    "                messages=messages,\n",
    "                max_completion_tokens=128,\n",
    "            )\n",
    "        except openai.LengthFinishReasonError as e:\n",
    "            raise e\n",
    "        except Exception as e:\n",
    "            print(\"caught exception generating chat completion\")\n",
    "            print(e)\n",
    "            global failing_trajectory\n",
    "            failing_trajectory = trajectory\n",
    "            raise e\n",
    "\n",
    "        choice = chat_completion.choices[0]\n",
    "        content = choice.message.content\n",
    "        assert isinstance(content, str)\n",
    "        trajectory.messages_and_choices.append(choice)\n",
    "\n",
    "        try:\n",
    "            apply_agent_move(game, content)\n",
    "        except ValueError:\n",
    "            trajectory.reward = -1 + (math.log(move_number + 1) / math.log(100))\n",
    "            break\n",
    "\n",
    "        move_number += 1\n",
    "        if check_winner(game[\"board\"]) is not None:\n",
    "            break\n",
    "\n",
    "        opponent_move = get_opponent_move(game)\n",
    "        game[\"board\"][opponent_move[0]][opponent_move[1]] = game[\"opponent_symbol\"]\n",
    "\n",
    "    winner = check_winner(game[\"board\"])\n",
    "\n",
    "    if winner == game[\"agent_symbol\"]:\n",
    "        trajectory.reward = 1\n",
    "        trajectory.metrics[\"win\"] = 1\n",
    "    elif winner == game[\"opponent_symbol\"]:\n",
    "        trajectory.reward = 0\n",
    "        trajectory.metrics[\"win\"] = 0\n",
    "    elif winner == \"draw\":\n",
    "        trajectory.reward = 0.5\n",
    "        trajectory.metrics[\"win\"] = 0.5\n",
    "\n",
    "    trajectory.metrics[\"num_moves\"] = move_number\n",
    "\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P40EAD_Jl21o"
   },
   "source": [
    "<a name=\"Loop\"></a>\n",
    "\n",
    "### Training Loop\n",
    "\n",
    "The training loop is where the magic happens. For each of the 100 steps defined below, the rollout function will be called 200 times in parallel. This means that 200 games will be played at once. Each game will produce a trajectory, which will be used to update the model.\n",
    "\n",
    "The `gather` step will wait for all of the trajectories to be generated, then it will delete all but the most recent checkpoint and train the model on the new trajectories.\n",
    "\n",
    "Inference will be blocked until the training is complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525,
     "referenced_widgets": [
      "16f5148272c346c2803a5d616114c6e8",
      "e7716bf4e3d3409e929b87c6e7aeb02d",
      "9acd9de32f164600a6b571d8b3e4aea0",
      "0bb61b3650b14f6fb01bd027be8b5d97",
      "9a774c4fdbf24443beb40c5d240a4f6a",
      "be63f344094140f8bf39167d08aced30",
      "42179796b28743d58b33449379a7731c",
      "dd6ae4a24d6c454a8b802da0a2befcf1",
      "480b9453b4c347f0ab503b255636b74e",
      "520935b1cda64df09bb20be17369ca90",
      "209d3e77538747d997d45d56616d7d7c",
      "3edc90a52eb84b2ab8424b1e2c453e79",
      "67b64ed3a452425b9c77aa9ea5f56378",
      "8e1fb4a676644382a3f8a3d2722d65cd",
      "f66314b5799f42b499a00af2a2a2f36d",
      "95f5ac39b729478ebebe5023bc1f898a",
      "36f4947660ec4f649190a136c2ccfa5f",
      "bb8b3677ed6a4a1d921bab4bd9549289",
      "eca6a51222eb4385972a49e1df77c5cb",
      "e501ff7be94f4489b332a26640f35a86",
      "e7a994a89806468fae5993dc0cc7678d",
      "ee69676e9c9c46ff9cbe0aab6a32917d",
      "86b30b17e44a4805bdbc0aaec99c7121",
      "c38f3b55cd0a4eecaf4e16383e9b7866",
      "96e92e8dc2c64e7f912c518895ce1b82",
      "1cdb97d49d484c5da5e59b620c0350f1",
      "8e4d4428fffb453f9dfe232c27604c2d",
      "81fbaa0882bb4545b01d8d405dbd8669",
      "49f63ad9d0184cba91629da075711396",
      "74f765b0dc564c9e9951fb701c1a0f96",
      "21e5f3e787f54875811efe5ba90cb3f2",
      "16d373ed36c64119a7c9af8ebb684755",
      "cc6166c85240444c97ec498b421832f0",
      "81207696ad5b46e4bb44619380524d6d",
      "4547b9ee3ae24bb58c43697df74405f6",
      "ac47c62bc7cb48a3bb665e7fa1ba8a5b",
      "38a27461a3d0483cab3bbb8d2ec5f8c0",
      "95841fb7258f4c99ac35692d46eb9ba5",
      "7f983bd49297443cada05fb22d7c6db9",
      "b93764e158c44c10a9db0bcf9b9d4c8b",
      "276e6b7782ac48009995b8a2cc08d3a2",
      "556787fcb3ed4382b1685c6c93457912",
      "66b12b59d762440282b333a9c279ad03",
      "1d90552d787a4e6ea1cc41e45eed6434",
      "fc04a546d3e84971b7d86a018911be73",
      "d44f9ef10d8542c0b58353249952e869",
      "19eb2869a98344e4bd85af612249774a",
      "af641256498d43e8862e70cf760bc0e5",
      "549fcfaa4b35426b92db3dea1dca6d4d",
      "6ee251e91b544767b02883bd8f70ed6d",
      "41983a48b92541fc97211694dcaae1b5",
      "6fc2c2358f21456b9661c7325b95aed0",
      "1076ee5e2c6740a2807ede2d842e47d7",
      "e39515b4a2114a6db7cd21f7861c94ad",
      "90ae7d38c74f4e158353ae30246d6e3e",
      "45b506de4f1f436e9fcb735ba62a4666",
      "a6512cd5ba8840cf9cd265a3980122b8",
      "ac070fbdeeeb4f1c86cd1f8ddc4f1805",
      "3aacf027c2c54a55a93a923e5d8211f3",
      "637fabb5e6bc4b0984b1ee1e5599858d",
      "d2f78151c41a400da8982923cd10922e",
      "8859bbc335e846ce8a784e783a73f27c",
      "d05780b7c3124f93a62ac8d67ca8be49",
      "b80bbc174e684448a4620a5a39016803",
      "0614e04847654827a8eeb20ce59292e8",
      "ec36d12c38024c27bdc6c6c26ede3377",
      "52a84a5af8744e2e9daf1f3144b69d6e",
      "6bb35ff8223547bb8e5d4d5203f92ea9",
      "50b2dc1c105a437c8178b676b76c4a2d",
      "5b72d6a4f27d4e5781ecb0a0752fb25e",
      "602cd40d584a4182baf5b171d032fec9",
      "9da42a9944ea47f6b568d537d1d95c33",
      "e0b4278d8c9d4b0297764b6fa607e913",
      "cb303c1793214480a9511ad638fabc9f",
      "49fc2f14acfb4970836cbecf95588cd2",
      "ca27db96d17a429588716823bcbb4b3e",
      "81c068ff75884ef192cc8e548bd40e66",
      "f713254473494ce0a9a33cb2d1a96da4",
      "20ee734628c7471987dabec2e7f129a9",
      "a1d05c04a882441f99b12ba0b526d1e2",
      "309429180e5840ecad81307af13f6089",
      "848bd1308a5f436d815e3bca6185c2b1",
      "bcce9b1518214d3b9e5b902f4d60bff9",
      "078a48dc20214bd8b12d9da821737ec4",
      "73206c4e130442e1b26db983532ee106",
      "97a0800969aa4e8c8a31e5531ed61fb1",
      "c4b160b53d3c4082985441abb529e511",
      "8c0f0aa1cb244b349397c5fbb9624824"
     ]
    },
    "id": "QcWKZgjIl21p",
    "outputId": "6d62455b-24f6-4c94-b4a7-5cb55315b00a"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "gather:   0%|          | 0/48 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16f5148272c346c2803a5d616114c6e8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:weave.trace.op:Warning: Traces will not be logged. Call weave.init to log your traces to a project.\n",
      " (subsequent messages of this type will be suppressed)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\"./.art/tic-tac-toe/models/001-script/history.jsonl\" not found\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3edc90a52eb84b2ab8424b1e2c453e79"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86b30b17e44a4805bdbc0aaec99c7121"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81207696ad5b46e4bb44619380524d6d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc04a546d3e84971b7d86a018911be73"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Packed 48 trajectories into 4 sequences of length 2048\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45b506de4f1f436e9fcb735ba62a4666"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "gather:   0%|          | 0/48 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52a84a5af8744e2e9daf1f3144b69d6e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No \"val/reward\" metric found in history\n",
      "Deleted checkpoint ./.art/tic-tac-toe/models/001-script/checkpoints/0000\n",
      "Packed 48 trajectories into 4 sequences of length 2048\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f713254473494ce0a9a33cb2d1a96da4"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "TRAINING_STEPS = 2\n",
    "ROLLOUTS_PER_STEP = 48\n",
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "for i in range(await model.get_step(), TRAINING_STEPS):\n",
    "    train_groups = await art.gather_trajectory_groups(\n",
    "        (\n",
    "            art.TrajectoryGroup(\n",
    "                rollout(model, TicTacToeScenario(step=i))\n",
    "                for _ in range(ROLLOUTS_PER_STEP)\n",
    "            )\n",
    "            for _ in range(1)\n",
    "        ),\n",
    "        pbar_desc=\"gather\",\n",
    "    )\n",
    "    await model.delete_checkpoints()\n",
    "    await model.train(train_groups, config=art.TrainConfig(learning_rate=LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCG8dnJbl21p"
   },
   "source": [
    "### Using the Model\n",
    "\n",
    "Just like that, you've trained an agent to play tic tac toe! Now it's time to use your model outside of ART, in the wild! The easiest way to do that is to load it from disk, where it was saved after each training step, and either run inference on it locally or upload it to a central hub like HuggingFace.\n",
    "\n",
    "Check out the code below for small demo of the model you just trained playing tic tac toe!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IT_kYqs_l21p",
    "outputId": "80b5a126-1731-485f-a762-1f90d94a26b6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model path: .art/tic-tac-toe/models/001-script/checkpoints/0002\n",
      "loading model from .art/tic-tac-toe/models/001-script/checkpoints/0002\n",
      "\n",
      "==((====))==  Unsloth 2025.8.6: Fast Qwen2 patching. Transformers: 4.53.2. vLLM: 0.9.2.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device does not support bfloat16. Will change to float16.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "move 1\n",
      "board:\n",
      "   1   2   3\n",
      "A  _ | _ | _\n",
      "B  _ | _ | _\n",
      "C  _ | _ | _\n",
      "\n",
      "agent move: <move>C1</move>\n",
      "updated board:\n",
      "   1   2   3\n",
      "A  _ | _ | _\n",
      "B  _ | _ | _\n",
      "C  x | _ | _\n",
      "\n",
      "\n",
      "move 3\n",
      "board:\n",
      "   1   2   3\n",
      "A  _ | o | _\n",
      "B  _ | _ | _\n",
      "C  x | _ | _\n",
      "\n",
      "agent move: <move>B3</move>\n",
      "updated board:\n",
      "   1   2   3\n",
      "A  _ | o | _\n",
      "B  _ | _ | x\n",
      "C  x | _ | _\n",
      "\n",
      "Invalid move on move 4: <move>A3</move>\n",
      "Reason: Square already occupied\n",
      "\n",
      "move 5\n",
      "board:\n",
      "   1   2   3\n",
      "A  _ | o | o\n",
      "B  _ | _ | x\n",
      "C  x | _ | _\n",
      "\n",
      "agent move: <move>C2</move>\n",
      "updated board:\n",
      "   1   2   3\n",
      "A  _ | o | o\n",
      "B  _ | _ | x\n",
      "C  x | x | _\n",
      "\n",
      "\n",
      "move 7\n",
      "board:\n",
      "   1   2   3\n",
      "A  _ | o | o\n",
      "B  _ | _ | x\n",
      "C  x | x | o\n",
      "\n",
      "agent move: <move>A1</move>\n",
      "updated board:\n",
      "   1   2   3\n",
      "A  x | o | o\n",
      "B  _ | _ | x\n",
      "C  x | x | o\n",
      "\n",
      "Invalid move on move 8: <move>B2</move>\n",
      "Reason: Square already occupied\n",
      "Invalid move on move 8: <move>C3</move>\n",
      "Reason: Square already occupied\n",
      "Invalid move on move 8: <move>A2</move>\n",
      "Reason: Square already occupied\n",
      "\n",
      "move 9\n",
      "board:\n",
      "   1   2   3\n",
      "A  x | o | o\n",
      "B  _ | o | x\n",
      "C  x | x | o\n",
      "\n",
      "agent move: <move>B1</move>\n",
      "updated board:\n",
      "   1   2   3\n",
      "A  x | o | o\n",
      "B  x | o | x\n",
      "C  x | x | o\n",
      "\n",
      "game finished in 9 moves\n",
      "game won! \ud83d\udcaa\n",
      "final board:\n",
      "\n",
      "   1   2   3\n",
      "A  x | o | o\n",
      "B  x | o | x\n",
      "C  x | x | o\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# example: .art/tic-tac-toe/models/002/checkpoints/0003\n",
    "print('model path:',  f\".art/{model.project}/models/{model.name}/checkpoints/{await model.get_step():04d}\")\n",
    "lora_model_path = (\n",
    "    f\".art/{model.project}/models/{model.name}/checkpoints/{await model.get_step():04d}\"\n",
    ")\n",
    "\n",
    "if Path(lora_model_path).exists():\n",
    "    import torch\n",
    "    from unsloth import FastLanguageModel\n",
    "\n",
    "    print(f\"loading model from {lora_model_path}\\n\")\n",
    "\n",
    "    peft_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=lora_model_path,\n",
    "        max_seq_length=16384,\n",
    "        dtype=torch.bfloat16,\n",
    "        load_in_4bit=True,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(peft_model)\n",
    "\n",
    "    game = generate_game()\n",
    "    move_number = 0\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"You are a tic-tac-toe player. You are playing against an opponent. Always choose the move most likely to lead to an eventual win. Return your move as an XML object with a single property 'move', like so: <move>A1</move>. Optional moves are 'A1', 'B3', 'C2', etc. You are the {game['agent_symbol']} symbol.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    if game[\"agent_symbol\"] == \"o\":\n",
    "        starting_opponent_move = get_opponent_move(game)\n",
    "        game[\"board\"][starting_opponent_move[0]][starting_opponent_move[1]] = game[\n",
    "            \"opponent_symbol\"\n",
    "        ]\n",
    "\n",
    "    while check_winner(game[\"board\"]) is None:\n",
    "        rendered_board = render_board(game)\n",
    "        messages.append({\"role\": \"user\", \"content\": rendered_board})\n",
    "\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages, return_tensors=\"pt\", add_generation_prompt=True\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        content = \"\"\n",
    "\n",
    "        def get_completion() -> str:\n",
    "            with torch.no_grad():\n",
    "                outputs = peft_model.generate(\n",
    "                    input_ids=inputs,\n",
    "                    max_new_tokens=100,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.7,\n",
    "                    top_p=0.9,\n",
    "                )\n",
    "                return tokenizer.decode(\n",
    "                    outputs[0][inputs.shape[1] :], skip_special_tokens=True\n",
    "                )\n",
    "\n",
    "        try:\n",
    "            content = get_completion()\n",
    "        except Exception as e:\n",
    "            print(\"caught exception generating chat completion\", e)\n",
    "            raise e\n",
    "\n",
    "        messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "\n",
    "        try:\n",
    "            apply_agent_move(game, content)\n",
    "            move_number += 1\n",
    "        except ValueError as e:\n",
    "            print(f\"Invalid move on move {move_number}: {content}\")\n",
    "            print(f\"Reason: {e}\")\n",
    "            continue\n",
    "\n",
    "        # print the board every move\n",
    "        print(f\"\\nmove {move_number}\")\n",
    "        print(f\"board:\\n{rendered_board}\")\n",
    "        print(f\"agent move: {content}\")\n",
    "        print(f\"updated board:\\n{render_board(game)}\")\n",
    "\n",
    "        if check_winner(game[\"board\"]) is not None:\n",
    "            break\n",
    "        move_number += 1\n",
    "\n",
    "        opponent_move = get_opponent_move(game)\n",
    "        game[\"board\"][opponent_move[0]][opponent_move[1]] = game[\"opponent_symbol\"]\n",
    "\n",
    "    winner = check_winner(game[\"board\"])\n",
    "\n",
    "    print(f\"game finished in {move_number} moves\")\n",
    "\n",
    "    if winner == game[\"agent_symbol\"]:\n",
    "        print(\"game won! \ud83d\udcaa\")\n",
    "    elif winner == game[\"opponent_symbol\"]:\n",
    "        print(\"game lost! \ud83d\ude22\")\n",
    "    elif winner == \"draw\":\n",
    "        print(\"draw! \ud83e\udd37\u200d\u2642\ufe0f\")\n",
    "\n",
    "    print(f\"final board:\\n\\n{render_board(game)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5mV606Dl21q"
   },
   "source": [
    "<div class=\"align-center\">\n",
    "<a href=\"https://github.com/openpipe/art\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://discord.gg/zbBHRUpwf4\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Discord.png\" height=\"50\"></a>\n",
    "<a href=\"https://openpipe.ai/blog/art-e-mail-agent\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_E_pill.png\" height=\"50\"></a>\n",
    "\n",
    "Questions? Join the Discord and ask away! For feature requests or to leave a star, visit our [Github](https://github.com/openpipe/art).\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}